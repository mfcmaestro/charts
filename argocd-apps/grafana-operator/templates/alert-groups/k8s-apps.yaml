######################################### EVERY 1m ###########################################

apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaAlertRuleGroup
metadata:
  name: 'kubernetes-apps-every-1m'
spec:
  name: 'every 1m'
  folderRef: k8s-apps
  instanceSelector:
    matchLabels:
      instance: {{ $.Values.global.instanceNameLabel }}
  interval: 1m0s
  rules:
    - uid: ddjpp1yijcuf4f
      title: KubePodCrashLooping
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job!=""}[5m])
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
          datasourceUid: __expr__
          model:
            conditions:
              - evaluator:
                  params:
                    - 0
                    - 0
                  type: gt
                operator:
                  type: and
                query:
                  params: []
                reducer:
                  params: []
                  type: avg
                type: query
            datasource:
              name: Expression
              type: __expr__
              uid: __expr__
            expression: A
            intervalMs: 1000
            maxDataPoints: 43200
            refId: B
            type: threshold
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: 'Pod {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod }}`}} ({{`{{ $labels.container }}`}}) is in waiting state (reason: "CrashLoopBackOff").'
        runbook_url: ""
        summary: Pod is crash looping.
      labels:
        notification_slack: "true"

    - uid: ddjpp1yivuc5cb
      title: KubePodNotReady
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                sum by (namespace, pod, job, cluster) (
                  max by(namespace, pod, job, cluster) (
                    kube_pod_status_phase{job!="", phase=~"Pending|Unknown|Failed"}
                  ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
                    1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
                  )
                )
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
        - refId: C
          relativeTimeRange:
            from: 600
          datasourceUid: __expr__
          model:
            conditions:
              - evaluator:
                  params:
                    - 0
                  type: gt
                operator:
                  type: and
                query:
                  params:
                    - C
                reducer:
                  params: []
                  type: last
                type: query
            datasource:
              type: __expr__
              uid: __expr__
            expression: A
            intervalMs: 1000
            maxDataPoints: 43200
            refId: C
            type: threshold
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: Pod {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod }}`}} has been in a non-ready state for longer than 15 minutes.
        runbook_url: ""
        summary: Pod has been in a non-ready state for more than 15 minutes.
      labels:
        notification_slack: "true"

    - uid: ddjpp1yj0u4u8d
      title: KubeDeploymentGenerationMismatch
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                kube_deployment_status_observed_generation{job!=""}
                  !=
                kube_deployment_metadata_generation{job!=""}
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: Deployment generation for {{`{{ $labels.namespace }}`}}/{{`{{ $labels.deployment }}`}} does not match, this indicates that the Deployment has failed but has not been rolled back.
        runbook_url: ""
        summary: Deployment generation mismatch due to possible roll-back.
      labels:
        notification_slack: "true"

    - uid: edjpp1yj8btvkb
      title: KubeDeploymentReplicasMismatch
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                (
                  kube_deployment_spec_replicas{job!=""}
                    >
                  kube_deployment_status_replicas_available{job!=""}
                ) and (
                  changes(kube_deployment_status_replicas_updated{job!=""}[10m])
                    ==
                  0
                )
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: Deployment {{`{{ $labels.namespace }}`}}/{{`{{ $labels.deployment }}`}} has not matched the expected number of replicas for longer than 15 minutes.
        runbook_url: ""
        summary: Deployment has not matched the expected number of replicas.
      labels:
        notification_slack: "true"

    - uid: ddjpp1yjdbmkgd
      title: KubeStatefulSetReplicasMismatch
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                (
                  kube_statefulset_status_replicas_ready{job!=""}
                    !=
                  kube_statefulset_status_replicas{job!=""}
                ) and (
                  changes(kube_statefulset_status_replicas_updated{job!=""}[10m])
                    ==
                  0
                )
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: StatefulSet {{`{{ $labels.namespace }}`}}/{{`{{ $labels.statefulset }}`}} has not matched the expected number of replicas for longer than 15 minutes.
        runbook_url: ""
        summary: StatefulSet has not matched the expected number of replicas.
      labels:
        notification_slack: "true"

    - uid: bdjpp1yjuswzkb
      title: KubeStatefulSetGenerationMismatch
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                kube_statefulset_status_observed_generation{job!=""}
                  !=
                kube_statefulset_metadata_generation{job!=""}
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: StatefulSet generation for {{`{{ $labels.namespace }}`}}/{{`{{ $labels.statefulset }}`}} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
        runbook_url: ""
        summary: StatefulSet generation mismatch due to possible roll-back.
      labels:
        notification_slack: "true"

    - uid: ddjpp1yk9sb28e
      title: KubeStatefulSetUpdateNotRolledOut
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                (
                  max without (revision) (
                    kube_statefulset_status_current_revision{job!=""}
                      unless
                    kube_statefulset_status_update_revision{job!=""}
                  )
                    *
                  (
                    kube_statefulset_replicas{job!=""}
                      !=
                    kube_statefulset_status_replicas_updated{job!=""}
                  )
                )  and (
                  changes(kube_statefulset_status_replicas_updated{job!=""}[5m])
                    ==
                  0
                )
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: StatefulSet {{`{{ $labels.namespace }}`}}/{{`{{ $labels.statefulset }}`}} update has not been rolled out.
        runbook_url: ""
        summary: StatefulSet update has not been rolled out.
      labels:
        notification_slack: "true"

    - uid: bdjpp1ykes3r4f
      title: KubeDaemonSetRolloutStuck
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                (
                  (
                    kube_daemonset_status_current_number_scheduled{job!=""}
                      !=
                    kube_daemonset_status_desired_number_scheduled{job!=""}
                  ) or (
                    kube_daemonset_status_number_misscheduled{job!=""}
                      !=
                    0
                  ) or (
                    kube_daemonset_status_updated_number_scheduled{job!=""}
                      !=
                    kube_daemonset_status_desired_number_scheduled{job!=""}
                  ) or (
                    kube_daemonset_status_number_available{job!=""}
                      !=
                    kube_daemonset_status_desired_number_scheduled{job!=""}
                  )
                ) and (
                  changes(kube_daemonset_status_updated_number_scheduled{job!=""}[5m])
                    ==
                  0
                )
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: DaemonSet {{`{{ $labels.namespace }}`}}/{{`{{ $labels.daemonset }}`}} has not finished or progressed for at least 15 minutes.
        runbook_url: ""
        summary: StatefulSet update has not been rolled out.
      labels:
        notification_slack: "true"

    - uid: ddjpp1ykjrwg0d
      title: KubeContainerWaiting
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: sum by (namespace, pod, container, job, cluster) (kube_pod_container_status_waiting_reason{job!=""})
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
        - refId: B
          datasourceUid: __expr__
          model:
            conditions:
              - evaluator:
                  params:
                    - 0
                    - 0
                  type: gt
                operator:
                  type: and
                query:
                  params: []
                reducer:
                  params: []
                  type: avg
                type: query
            datasource:
              name: Expression
              type: __expr__
              uid: __expr__
            expression: A
            intervalMs: 1000
            maxDataPoints: 43200
            refId: B
            type: threshold
      noDataState: OK
      execErrState: OK
      for: 1h0m0s
      annotations:
        description: pod/{{`{{ $labels.pod }}`}} in namespace {{`{{ $labels.namespace }}`}} on container {{`{{ $labels.container}}`}} has been in waiting state for longer than 1 hour.
        runbook_url: ""
        summary: Pod container waiting longer than 1 hour.
      labels:
        notification_slack: "true"

    - uid: adjpp1ykr9lhce
      title: KubeDaemonSetNotScheduled
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                kube_daemonset_status_desired_number_scheduled{job!=""}
                  -
                kube_daemonset_status_current_number_scheduled{job!=""}
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
          datasourceUid: __expr__
          model:
            conditions:
              - evaluator:
                  params:
                    - 0
                    - 0
                  type: gt
                operator:
                  type: and
                query:
                  params: []
                reducer:
                  params: []
                  type: avg
                type: query
            datasource:
              name: Expression
              type: __expr__
              uid: __expr__
            expression: A
            hide: false
            intervalMs: 1000
            maxDataPoints: 43200
            refId: B
            type: threshold
      noDataState: OK
      execErrState: OK
      for: 10m0s
      annotations:
        description: '{{`{{ $value }}`}} Pods of DaemonSet {{`{{ $labels.namespace }}`}}/{{`{{ $labels.daemonset }}`}} are not scheduled.'
        runbook_url: ""
        summary: DaemonSet pods are not scheduled.
      labels:
        notification_slack: "true"

    - uid: cdjpp1ykyraioa
      title: KubeDaemonSetMisScheduled
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: kube_daemonset_status_number_misscheduled{job!=""}
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
          datasourceUid: __expr__
          model:
            conditions:
              - evaluator:
                  params:
                    - 0
                    - 0
                  type: gt
                operator:
                  type: and
                query:
                  params: []
                reducer:
                  params: []
                  type: avg
                type: query
            datasource:
              name: Expression
              type: __expr__
              uid: __expr__
            expression: A
            hide: false
            intervalMs: 1000
            maxDataPoints: 43200
            refId: B
            type: threshold
      noDataState: OK
      execErrState: OK
      for: 10m0s
      annotations:
        description: '{{`{{ $value }}`}} Pods of DaemonSet {{`{{ $labels.namespace }}`}}/{{`{{ $labels.daemonset }}`}} are running where they are not supposed to run.'
        runbook_url: ""
        summary: DaemonSet pods are misscheduled.
      labels:
        notification_slack: "true"

        - uid: cdjpp1ykyraioa
      title: KubeJobFailed
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: kube_job_failed{job!=""}
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
          datasourceUid: __expr__
          model:
            conditions:
              - evaluator:
                  params:
                    - 0
                    - 0
                  type: gt
                operator:
                  type: and
                query:
                  params: []
                reducer:
                  params: []
                  type: avg
                type: query
            datasource:
              name: Expression
              type: __expr__
              uid: __expr__
            expression: A
            intervalMs: 1000
            maxDataPoints: 43200
            refId: B
            type: threshold
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: Job {{`{{ $labels.namespace }}`}}/{{`{{ $labels.job_name }}`}} failed to complete. Removing failed job after investigation should clear this alert.
        runbook_url: ""
        summary: Job failed to complete.
      labels:
        notification_slack: "true"

    - uid: cdjpp1yliqha8f
      title: KubeHpaReplicasMismatch
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                (kube_horizontalpodautoscaler_status_desired_replicas{job!=""}
                  !=
                kube_horizontalpodautoscaler_status_current_replicas{job!=""})
                  and
                (kube_horizontalpodautoscaler_status_current_replicas{job!=""}
                  >
                kube_horizontalpodautoscaler_spec_min_replicas{job!=""})
                  and
                (kube_horizontalpodautoscaler_status_current_replicas{job!=""}
                  <
                kube_horizontalpodautoscaler_spec_max_replicas{job!=""})
                  and
                changes(kube_horizontalpodautoscaler_status_current_replicas{job!=""}[15m]) == 0
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: HPA {{`{{ $labels.namespace }}`}}/{{`{{ $labels.horizontalpodautoscaler  }}`}} has not matched the desired number of replicas for longer than 15 minutes.
        runbook_url: ""
        summary: HPA has not matched desired number of replicas.
      labels:
        notification_slack: "true"

    - uid: fdjpp1ylq86bke
      title: KubeHpaMaxedOut
      condition: A
      data:
        - refId: A
          relativeTimeRange:
            from: 600
          datasourceUid: grafanacloud-kropyva-prom
          model:
            datasource:
              type: prometheus
              uid: grafanacloud-kropyva-prom
            editorMode: code
            expr: |-
                kube_horizontalpodautoscaler_status_current_replicas{job!=""}
                  ==
                kube_horizontalpodautoscaler_spec_max_replicas{job!=""}
            instant: true
            intervalMs: 1000
            legendFormat: __auto
            maxDataPoints: 43200
            range: false
            refId: A
      noDataState: OK
      execErrState: OK
      for: 15m0s
      annotations:
        description: HPA {{`{{ $labels.namespace }}`}}/{{`{{ $labels.horizontalpodautoscaler }}`}} has been running at max replicas for longer than 15 minutes.
        runbook_url: ""
        summary: HPA is running at max replicas.
      labels:
        notification_slack: "true"
